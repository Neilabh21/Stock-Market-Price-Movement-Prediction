# -*- coding: utf-8 -*-
"""Copy of Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XGE4zyuantYa8cMwIPYlSkg7fKVuKbhl
"""

import json
import numpy as np
import requests
from bs4 import BeautifulSoup
import pandas as pd
import random
from textblob import TextBlob
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from nltk.corpus import stopwords
nltk.download('stopwords')

titles = []
for i in range(498):
  temp_list = []
  try:
    list_1 = requests.get("https://api.pushshift.io/reddit/search/submission/?subreddit=finance&after={}d&before={}d&fields=title&sort=desc&sort_type=score&size=50".format(i+1, i)).json()['data']
  except:
    continue
  for keys in list_1:
    temp_list.append(keys['title'])
  text = ' '.join(temp_list)
  contentBlob = TextBlob(text).lower()
  n_tokens_content = len(contentBlob.words)
  n_unique_tokens = len(list(set(contentBlob.words)))
  content_sentiment_polarity = contentBlob.sentiment.polarity
  content_subjectivity = contentBlob.sentiment.subjectivity
  titles.append([498 - i, text, content_sentiment_polarity, content_subjectivity])
  print(i)

df = pd.DataFrame(titles, columns = ["Date", "Text", "Polarity", "Subjectivity"])

df

df.to_csv("News.csv")